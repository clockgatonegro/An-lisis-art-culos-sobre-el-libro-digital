{
    "collab_server" : "",
    "contents" : "library(tidytext)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(wordcloud)\nlibrary(tidyr)\nlibrary(igraph)\nlibrary(ggraph)\n\n#Reconocer texto en español\nSys.setlocale(\"LC_ALL\", \"ES_ES.UTF-8\")\n\n##Importar el texto a R como un data frame por parrafos\ndataframe_articulos = read.csv(\"articulos.csv\")  \nhead(dataframe_articulos)\n\ndataframe_articulos$fecha <- as.Date(dataframe_articulos$fecha,\"%m/%d/%Y\")\n\n\nclass(dataframe_articulos$fecha)\n\n#Convertir factores a caracter strings\ndataframe_articulos %>% mutate_if(is.factor, as.character) -> dataframe_articulos\nhead(dataframe_articulos)\n\n#volverla un tibble\nparrafos_articulos <- as_data_frame(dataframe_articulos)\nhead(parrafos_articulos)\n\n#Unnest por palabras\npalabras_articulos <- parrafos_articulos %>% unnest_tokens(palabras,texto)\n\n#volver las stop words un tibble\nstopwords_df <- data_frame(line = 1:308, palabras = stopwords(\"spanish\"))\n\n# Quitar las stop words del data frame\npalabras_articulos <- palabras_articulos %>% anti_join(stopwords_df)\n\n#tabla organizada por \npalabras_articulos %>% count(palabras, sort = TRUE) \n\n#Histograma de palabras más usadas\npalabras_articulos %>% count(palabras, sort = TRUE) %>% filter(n > 50) %>%\n  mutate(word = reorder(palabras, n)) %>%\n  ggplot(aes(palabras, n)) +\n  geom_col() +\n  xlab(NULL) +\n  coord_flip()\n\n#Ocurrencia de artículos por fecha y categoría\nggplot(palabras_articulos, aes(fecha, categoría)) + geom_point(colour = 'red') + xlab(\"Tiempo\") + ylab(\"Categoría\")\n\n#Ocurrencia de artículos por fecha y sección\nggplot(palabras_articulos, aes(fecha, sección)) + geom_point(colour = 'green') + xlab(\"Tiempo\") + ylab(\"Sección\")\n\n#Ocurrencia de artículos por título\nggplot(palabras_articulos, aes(fecha, titulo)) + geom_point(colour = 'blue') + xlab(\"Tiempo\") + ylab(\"título\")\n\n#generar un wordcloud\npalabras_articulos %>% count(palabras) %>%\n  with(wordcloud(palabras, n, max.words = 200))\n\n#generación de n-grams (bigramas)\narticulos_bigramas <- unnest_tokens(parrafos_articulos, bigramas, texto, token = \"ngrams\", n = 2)\narticulos_bigramas %>%\n  count(bigramas, sort = TRUE)\n\n#separar bigramas por columna\nbigramas_separados <- articulos_bigramas %>%\n  separate(bigramas, c(\"palabra1\", \"palabra2\"), sep = \" \")\n\n#Filtrar stop words\nbigramas_filtrados <- bigramas_separados %>%\n  filter(!palabra1 %in% stopwords_df$palabras) %>%\n  filter(!palabra2 %in% stopwords_df$palabras)\n\n#Contar los bigramas sin las stopwords organizados de mayor a menor\nbigramas_conteo <- bigramas_filtrados %>% \n  count(palabra1, palabra2, sort = TRUE)\n\n#un tibble con los bigramas unidos de nuevo en una sola columna\nbigramas_unidos <- bigramas_filtrados %>%\n  unite(bigramas, palabra1, palabra2, sep = \" \")\nbigramas_unidos\n\n#encontrar los trigramas\narticulos_trigramas <- unnest_tokens(parrafos_articulos, trigramas, texto, token = \"ngrams\", n = 3) \narticulos_trigramas%>%\ncount(trigramas, sort = TRUE)  \n\ntrigramas_separados <- separate(articulos_trigramas,trigramas, c(\"palabra1\", \"palabra2\", \"palabra3\"), sep = \" \") \n  \ntrigramas_filtrados <-trigramas_separados%>%  \n  filter(!palabra1 %in% stopwords_df$palabras)%>%\n  filter(!palabra2 %in% stopwords_df$palabras)%>%\n  filter(!palabra3 %in% stopwords_df$palabras) %>%\n  count(palabra1, palabra2, palabra3, sort = TRUE)\n\n#Filtrar bigramas por la palabra libro\nbigramas_filtrados %>%\n  filter(palabra1 == \"libro\") %>%\n  count(titulo, palabra2, sort = TRUE)\n\n#Filtrar bigramas por la palabra mercado\nbigramas_filtrados %>%\n  filter(palabra1 == \"mercado\") %>%\n  count(titulo, palabra2, sort = TRUE)\n\n#Generar un tabla con las columnas palabra1, palabra2 y \nbigramas_grafo <- bigramas_conteo %>%\n  filter(n > 4) %>%\n  graph_from_data_frame()\n\n#Visualizar la red de bigramas\nset.seed(2017)\nggraph(bigramas_grafo, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), vjust = 1, hjust = 1)\n\n#Visualizar la red usando tranparencia\na <- grid::arrow(type = \"closed\", length = unit(.15, \"inches\"))\nset.seed(2016)\nggraph(bigramas_grafo, layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,\n                 arrow = a, end_cap = circle(.07, 'inches')) +\n  geom_node_point(color = \"lightblue\", size = 5) +\n  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n  theme_void()\n\n#Visualizar la red de artículos y palabras\narticulosporpalabra <- select(palabras_articulos, titulo, palabras) %>% \n   count(titulo, palabras, sort = TRUE)\n\npalarticulo_grafo <- articulosporpalabra %>%\n  filter(n > 5) %>%\n  graph_from_data_frame()\n\n#asignar un color a los títulos y otro color a las palabras\nV(palarticulo_grafo)$color[1:37] <- \"#4ECDC4\"\nV(palarticulo_grafo)$color[38:142] <- \"#C7F464\"\n\nset.seed(2017)\nggraph(palarticulo_grafo, layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,\n  arrow = a, end_cap = circle(.07, 'inches')) +\n  geom_node_point(color=V(palarticulo_grafo)$color, size = 5) +\n  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n  theme_void()\n\n\n#Visualizar la red de articulos y bigramas\narticulosporbigrama <- select(bigramas_unidos, titulo, bigramas) %>% \n  count(titulo, bigramas, sort = TRUE)\n\nbigrarticulo_grafo <- articulosporbigrama %>%\n  filter(n > 1) %>%\n  graph_from_data_frame()\n\n#para n>2 = V(bigrarticulo_grafo)[29] hasta [82] || para n>1 = V(bigrarticulo_grafo)[41] hasta [236]\nV(bigrarticulo_grafo)$name[41]\nV(bigrarticulo_grafo)$color[1:41] <- \"#4ECDC4\"\nV(bigrarticulo_grafo)$color[42:236] <- \"#C7F464\"\n\nggraph(bigrarticulo_grafo, layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,\n                 arrow = a, end_cap = circle(.07, 'inches')) +\n  geom_node_point(color=V(bigrarticulo_grafo)$color, size = 5 )+\n  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n  theme_void()",
    "created" : 1497906363194.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "885342351",
    "id" : "49A7C6E1",
    "lastKnownWriteTime" : 1498107490,
    "last_content_update" : 1498107490127,
    "path" : "~/Documents/Articulos Tesis/Text Mining R.R",
    "project_path" : "Text Mining R.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}